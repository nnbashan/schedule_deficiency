{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22f4b8e-e5a2-447d-99f5-6c0e71633355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "\n",
    "# This notebook includes the analysis tools used in the final presentation\n",
    "\n",
    "# -------------------------\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.ticker as mticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ecee47-9733-4e5b-b9b7-0e995e439aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_queries = {\n",
    "    \"2023-1\": \"service_date >= '2022-12-18' & service_date <= '2023-03-11'\",\n",
    "    \"2023-2\": \"service_date >= '2023-03-12' & service_date <= '2023-07-02'\",\n",
    "    \"2023-3\": \"service_date > '2023-07-02' & service_date <= '2023-08-26'\",\n",
    "    \"2023-4\"  : \"service_date >= '2023-08-27' & service_date <= '2023-12-16'\",\n",
    "    \"2024-1\": \"service_date >= '2023-12-17' & service_date <= '2024-04-06'\",\n",
    "    \"2024-2\": \"service_date >= '2024-04-07' & service_date <= '2024-06-15'\",\n",
    "    \"2024-3\": \"service_date >= '2024-06-16' & service_date <= '2024-08-24'\",\n",
    "    \"2024-4\"  : \"service_date > '2024-08-24' & service_date <= '2024-12-14'\",\n",
    "    \"2025-1\": \"service_date > '2024-12-14' & service_date <= '2025-04-06'\",\n",
    "    \"2025-2\": \"service_date > '2025-04-06' & service_date <= '2025-06-14'\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6e9793-8301-4534-b453-6cf6a2abaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "\n",
    "# Read pre-calculated dataframes from data_process.ipynb\n",
    "# df_all: cleaned AVL data\n",
    "# sd_all: trip-level runtimes\n",
    "# combined: HASTUS schedules between 2023-1 to 2025-3\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "df_all = pd.read_csv('df_all.csv')\n",
    "\n",
    "df_all[\"service_date\"]     = pd.to_datetime(df_all[\"service_date\"],     format=\"%Y-%m-%d\",              errors=\"coerce\")\n",
    "df_all[\"scheduled_boston\"] = pd.to_datetime(df_all[\"scheduled_boston\"], format=\"%Y-%m-%d %H:%M:%S\",     errors=\"coerce\")\n",
    "df_all[\"actual_boston\"]    = pd.to_datetime(df_all[\"actual_boston\"],    format=\"%Y-%m-%d %H:%M:%S\",     errors=\"coerce\")\n",
    "\n",
    "all_available_routes = df_all.drop_duplicates('route_id')\n",
    "all_available_routes = all_available_routes[all_available_routes['route_id'].astype(str).str.strip().str.fullmatch(r'\\d+')]\n",
    "\n",
    "\n",
    "\n",
    "sd_all = pd.read_csv('sd_all.csv')\n",
    "sd_all['service_date']    = pd.to_datetime(sd_all['service_date'])\n",
    "\n",
    "\n",
    "combined = pd.read_csv('combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f979951-6423-4430-8c0c-63de4deeb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns={'timepointid':'time_point_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9627127-63fd-488a-a157-2ae078b52f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "\n",
    "# One digit routes (such as Route 1) are recorded as '01' in database, so we are assigning a \n",
    "# route key to avoid integer/string mismatch\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "def _route_key(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "\n",
    "    m = re.fullmatch(r'0*(\\d+)([A-Za-z]*)', s)\n",
    "    if m:\n",
    "        num = str(int(m.group(1)))           # drop leading zeros\n",
    "        suf = m.group(2).upper()             # normalize suffix casing\n",
    "        return num + suf\n",
    "\n",
    "    return s.upper()\n",
    "    \n",
    "if 'route_key' not in sd_all.columns:\n",
    "    sd_all = sd_all.copy()\n",
    "    sd_all['route_key'] = sd_all['route_id'].map(_route_key)\n",
    "\n",
    "if 'route_key' not in combined.columns:\n",
    "    combined = combined.copy()\n",
    "    combined['route_key'] = combined['Route'].map(_route_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db46733-4ce2-4fae-bbef-5a4fc9d879c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "\n",
    "# For practicality we are dropping the route names that include a letter (SL1, 34E..)\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "combined = combined[combined['Route'].astype(str).str.strip().str.fullmatch(r'\\d+')]\n",
    "\n",
    "# There are some routes that have entries in the schedule but not on in the AVL data after cleaning (714,1013)\n",
    "\n",
    "combined_28 = combined[combined['Route'].astype(int).isin(sd_all['route_id'].astype(int).unique())]\n",
    "\n",
    "combined_28['time_dir'] = combined_28['Start'].astype(str)+combined_28['Direction'].astype(str)+ \\\n",
    "         combined_28['rat_id'].astype(str)+combined_28['DOW'].astype(str)+combined_28['type_d'].astype(str)+combined_28['Route'].astype(str)\n",
    "\n",
    "# There are some routes that have multiple busses running the same schedule (variant?)\n",
    "\n",
    "cnts = combined_28.value_counts('time_dir').reset_index()\n",
    "cnts = cnts[cnts['count']==1]\n",
    "combined_28 = combined_28[combined_28['time_dir'].isin(cnts['time_dir'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3faf8dc0-68a5-4c6f-a4a6-ae50bedd6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['delay_min'] = (df_all['actual_boston'] - df_all['scheduled_boston'])\\\n",
    "                        .dt.total_seconds() / 60\n",
    "\n",
    "starts = df_all[(df_all['point_type']=='Startpoint')]\n",
    "id_keeps = starts[(starts['delay_min']<=15)&(starts['delay_min']>-10)]['half_trip_id']\n",
    "\n",
    "df_all_cleaned = df_all[df_all['half_trip_id'].isin(id_keeps)]\n",
    "\n",
    "sd_all_cleaned = sd_all[sd_all['half_trip_id'].isin(id_keeps)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91114a2-3713-4554-8c0b-c7d59e8a9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9589006370383601\n",
      "0.9605531021196033\n"
     ]
    }
   ],
   "source": [
    "print(len(df_all_cleaned)/len(df_all))\n",
    "print(len(sd_all_cleaned)/len(sd_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907cc70b-9681-4e69-959e-4a044dec85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd_all_mrg = sd_all.merge(combined_28[['time_dir','Act_Layover','Variant']])\n",
    "\n",
    "\n",
    "sd_all_mrg = (\n",
    "    sd_all_mrg[pd.to_numeric(sd_all_mrg['Act_Layover'], errors='coerce').notna()]\n",
    "      .assign(Act_Layover=lambda df: df['Act_Layover'].astype(float))\n",
    ")\n",
    "\n",
    "sd_all_mrg['schdLO']  = sd_all_mrg['scheduled_run'] + sd_all_mrg['Act_Layover']\n",
    "\n",
    "\n",
    "agg = sd_all_mrg.groupby('time_dir').agg(\n",
    "    actual_run_q90=('actual_run', lambda x: x.quantile(0.90)),\n",
    "    mean_schd     =('scheduled_run',    'mean'),\n",
    "    mean_lo     =('Act_Layover',    'mean')).reset_index()\n",
    "\n",
    "df_out = sd_all_mrg.merge(\n",
    "agg[['time_dir','actual_run_q90','mean_schd','mean_lo']],\n",
    "on='time_dir',\n",
    "how='left'\n",
    ")\n",
    "df_out = df_out.drop_duplicates('time_dir')[['actual_run_q90','mean_schd','mean_lo','time_dir','season','holiday','direction_id','schedule_type','hour_Startpoint',\n",
    "                                             'scheduledhm_Startpoint','DOW','route_id','schdLO','Variant']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c64d569-a096-4d63-a10b-73889640cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deficiency_ratio(df: pd.DataFrame, bin_col: str) -> pd.Series:\n",
    "    \n",
    "        g = (df\n",
    "             .groupby(['route_key', bin_col], as_index=False)\n",
    "             .agg(actual_run=('actual_run', lambda x: x.quantile(0.9)),  \n",
    "                  schdLO     =('schdLO',     'mean')))\n",
    "    \n",
    "        g['pos_diff'] = (g['actual_run'] - g['schdLO']).clip(lower=0)\n",
    "    \n",
    "        sums = g.groupby('route_key').agg(\n",
    "            num=('pos_diff', 'sum'),\n",
    "            den=('schdLO',   'sum')\n",
    "        )\n",
    "        return sums['num'] / sums['den']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a76b303-47cd-4219-a89f-2f77dc35a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surplus_ratio(df: pd.DataFrame, bin_col: str) -> pd.Series:\n",
    "    \n",
    "        g = (df\n",
    "             .groupby(['route_key', bin_col], as_index=False)\n",
    "             .agg(actual_run=('actual_run', lambda x: x.quantile(0.9)),   \n",
    "                  schdLO     =('schdLO',     'mean')))\n",
    "    \n",
    "        g['pos_diff'] = (g['schdLO'] - g['actual_run']).clip(lower=0)\n",
    "    \n",
    "        sums = g.groupby('route_key').agg(\n",
    "            num=('pos_diff', 'sum'),\n",
    "            den=('schdLO',   'sum')\n",
    "        )\n",
    "        return sums['num'] / sums['den']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64264995-0210-42d9-b73c-f120968065ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:43<00:00, 12.91s/it]\n"
     ]
    }
   ],
   "source": [
    "outs = pd.DataFrame()\n",
    "outs2 = pd.DataFrame()\n",
    "\n",
    "for season in tqdm(['2025-1','2024-1','2025-2','2024-2','2024-3','2023-3','2024-4','2023-4']):\n",
    "    for dir in ['Outbound','Inbound']:\n",
    "        mask = (\n",
    "            (sd_all_mrg['season'] == season) &\n",
    "            (sd_all_mrg['direction_id'] == dir) &\n",
    "            (sd_all_mrg['DOW'] == 'Weekday')\n",
    "        )\n",
    "        core = sd_all_mrg.loc[mask,  \n",
    "                              ['route_key', 'hour_Startpoint', 'scheduledhm_Startpoint',\n",
    "                               'actual_run', 'schdLO']]\n",
    "        \n",
    "        defs_rt = deficiency_ratio(core, 'scheduledhm_Startpoint') \n",
    "        surp_rt = surplus_ratio(core, 'scheduledhm_Startpoint')  \n",
    "\n",
    "        \n",
    "        out = (pd.concat({'Deficit Percent': defs_rt}, axis=1)\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'route_key': 'route'}))\n",
    "\n",
    "        out2 = (pd.concat({'Surplus Percent': surp_rt}, axis=1)\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'route_key': 'route'}))\n",
    "        \n",
    "        out['season'] = season\n",
    "        out['dir'] = dir\n",
    "\n",
    "        out2['season'] = season\n",
    "        out2['dir'] = dir\n",
    "        \n",
    "        outs = pd.concat([outs,out])\n",
    "        outs2 = pd.concat([outs2,out2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66edb857-b42f-4ba4-936a-0e7ac5acb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_ = outs.groupby(['route','season']).mean('Deficit Percent').reset_index()\n",
    "outs_2 = outs2.groupby(['route','season']).mean('Surplus Percent').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1802fe-190b-4ba3-91f8-5b0770849da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: route_rating_deltas.xlsx\n"
     ]
    }
   ],
   "source": [
    "#defs = pd.read_excel('Schedule Deficiency one route_data (2).xlsx')\n",
    "\n",
    "def build_rating_comparison_excel(defs: pd.DataFrame, out_path=\"route_rating_deltas.xlsx\"):\n",
    "    \n",
    "    val_col = \"Deficit Percent\"\n",
    "    df = (defs[['route', 'season', val_col]]\n",
    "          .copy())\n",
    "    df['route'] = df['route'].astype(str).str.strip()\n",
    "    df = df.groupby(['route', 'season'], as_index=False)[val_col].mean()\n",
    "\n",
    "    pair_map = {\n",
    "        '2025-2': '2024-2',\n",
    "        '2025-1': '2024-1',\n",
    "        '2024-3': '2023-3',\n",
    "        '2024-4'  : '2023-4',\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for cur, prev in pair_map.items():\n",
    "        cur_df  = df[df['season'] == cur][['route', val_col]].rename(columns={val_col: 'current_value'})\n",
    "        prev_df = df[df['season'] == prev][['route', val_col]].rename(columns={val_col: 'prior_value'})\n",
    "        merged = pd.merge(cur_df, prev_df, on='route', how='inner')\n",
    "        if merged.empty:\n",
    "            continue\n",
    "        merged['pair'] = f'{cur} vs {prev}'\n",
    "        merged['current_rating'] = cur\n",
    "        merged['prior_rating'] = prev\n",
    "        merged['change'] = merged['current_value'] - merged['prior_value']\n",
    "        rows.append(merged[['route','pair','prior_rating','prior_value','current_rating','current_value','change']])\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"No overlapping season pairs found for the provided data.\")\n",
    "\n",
    "    long = pd.concat(rows, ignore_index=True)\n",
    "    long = long.sort_values(['route','pair'])\n",
    "\n",
    "    matrix = (long\n",
    "              .pivot(index='route', columns='pair', values='change')\n",
    "              .sort_index())\n",
    "    \n",
    "    THRESH = 0.005\n",
    "    red_count = (matrix > THRESH).sum(axis=1)           # how many red cells per route\n",
    "    pos_sum   = matrix.clip(lower=0).sum(axis=1)        # sum of positive changes\n",
    "    order = (pd.DataFrame({'red': red_count, 'pos_sum': pos_sum}, index=matrix.index)\n",
    "             .sort_values(['red', 'pos_sum'], ascending=[False, False]).index)\n",
    "    matrix = matrix.loc[order]\n",
    "    with pd.ExcelWriter(out_path, engine='xlsxwriter') as writer:\n",
    "        long.to_excel(writer, sheet_name='Long', index=False)\n",
    "        matrix.to_excel(writer, sheet_name='Matrix')\n",
    "\n",
    "        wb = writer.book\n",
    "\n",
    "        pct_fmt   = wb.add_format({'num_format': '0.0%'})\n",
    "        red_fmt   = wb.add_format({'bg_color': '#FFC7CE', 'font_color': '#000000', 'num_format': '0.0%'})\n",
    "        green_fmt = wb.add_format({'bg_color': '#C6EFCE', 'font_color': '#000000', 'num_format': '0.0%'})\n",
    "        yellow_fmt= wb.add_format({'bg_color': '#FFEB9C', 'font_color': '#000000', 'num_format': '0.0%'})\n",
    "\n",
    "        ws = writer.sheets['Matrix']\n",
    "        ws.set_column(0, 0, 12) \n",
    "        if not matrix.empty:\n",
    "            nrows, ncols = matrix.shape\n",
    "            first_row, first_col = 1, 1 \n",
    "            last_row  = first_row + nrows - 1\n",
    "            last_col  = first_col + ncols - 1\n",
    "\n",
    "            ws.set_column(first_col, last_col, 14, pct_fmt)\n",
    "\n",
    "            ws.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                                  {'type': 'cell', 'criteria': '>', 'value': 0.005, 'format': red_fmt})\n",
    "            ws.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                                  {'type': 'cell', 'criteria': '<', 'value': -0.005, 'format': green_fmt})\n",
    "            ws.conditional_format(first_row, first_col, last_row, last_col,\n",
    "                                  {'type': 'cell', 'criteria': 'between',\n",
    "                                   'minimum': -0.005, 'maximum': 0.005, 'format': yellow_fmt})\n",
    "            ws.freeze_panes(1, 1)\n",
    "\n",
    "        ws2 = writer.sheets['Long']\n",
    "        ws2.set_column(0, len(long.columns)-1, 14)\n",
    "        for col_name in ['prior_value', 'current_value', 'change']:\n",
    "            cidx = list(long.columns).index(col_name)\n",
    "            ws2.set_column(cidx, cidx, 12, pct_fmt)\n",
    "\n",
    "        cidx = list(long.columns).index('change')\n",
    "        if len(long) > 0:\n",
    "            ws2.conditional_format(1, cidx, len(long), cidx,\n",
    "                                   {'type': 'cell', 'criteria': '>', 'value': 0.05, 'format': red_fmt})\n",
    "            ws2.conditional_format(1, cidx, len(long), cidx,\n",
    "                                   {'type': 'cell', 'criteria': '<', 'value': -0.05, 'format': green_fmt})\n",
    "            ws2.conditional_format(1, cidx, len(long), cidx,\n",
    "                                   {'type': 'cell', 'criteria': 'between',\n",
    "                                    'minimum': -0.05, 'maximum': 0.05, 'format': yellow_fmt})\n",
    "            ws2.freeze_panes(1, 0)\n",
    "\n",
    "    return out_path, long, matrix\n",
    "\n",
    "out_path, long_df, matrix_df = build_rating_comparison_excel(outs_, \"route_rating_deltas.xlsx\")\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc303d2-2cac-4a5c-93cf-bb883b888234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
